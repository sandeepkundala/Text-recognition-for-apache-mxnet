{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from mxboard import SummaryWriter\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd, gluon\n",
    "from mxnet.gluon.model_zoo.vision import resnet34_v1\n",
    "import numpy as np\n",
    "from skimage import transform as skimage_tf\n",
    "from skimage import exposure\n",
    "from tqdm import tqdm\n",
    "np.seterr(all='raise')\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "mx.random.seed(1)\n",
    "\n",
    "from ocr.utils.iam_dataset import IAMDataset, resize_image\n",
    "from ocr.utils.draw_text_on_image import draw_text_on_image\n",
    "\n",
    "alphabet_encoding = r' $!\"#&\\'()~^<>[]|_{}=@%*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "alphabet_dict = {alphabet_encoding[i]:i for i in range(len(alphabet_encoding))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(gluon.HybridBlock):\n",
    "    '''The encoder layer takes the image features from a CNN. The image features are transposed so that the LSTM \n",
    "    slices of the image features can be sequentially fed into the LSTM from left to right (and back via the\n",
    "    bidirectional LSTM). \n",
    "    '''\n",
    "    def __init__(self, hidden_states=200, rnn_layers=1, max_seq_len=100, **kwargs):\n",
    "        self.max_seq_len = max_seq_len\n",
    "        super(EncoderLayer, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.lstm = mx.gluon.rnn.LSTM(hidden_states, rnn_layers, bidirectional=True)\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = x.transpose((0, 3, 1, 2))\n",
    "        x = x.flatten()\n",
    "        x = x.split(num_outputs=self.max_seq_len, axis=1) # (SEQ_LEN, N, CHANNELS)\n",
    "        x = F.concat(*[elem.expand_dims(axis=0) for elem in x], dim=0)\n",
    "        x = self.lstm(x)\n",
    "        x = x.transpose((1, 0, 2)) #(N, SEQ_LEN, HIDDEN_UNITS)\n",
    "        return x\n",
    "\n",
    "class CNNBiLSTM(gluon.HybridBlock):\n",
    "    '''The CNN-biLSTM to recognise handwriting text given an image of handwriten text.\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_downsamples: int, default 2\n",
    "        The number of times to downsample the image features. Each time the features are downsampled, a new LSTM\n",
    "        is created. \n",
    "    resnet_layer_id: int, default 4\n",
    "        The layer ID to obtain features from the resnet34\n",
    "    lstm_hidden_states: int, default 200\n",
    "        The number of hidden states used in the LSTMs\n",
    "    lstm_layers: int, default 1\n",
    "        The number of layers of LSTMs to use\n",
    "    '''\n",
    "    FEATURE_EXTRACTOR_FILTER = 64\n",
    "    def __init__(self, num_downsamples=2, resnet_layer_id=4, rnn_hidden_states=200, rnn_layers=1, max_seq_len=100, ctx=mx.gpu(), **kwargs):\n",
    "        super(CNNBiLSTM, self).__init__(**kwargs)\n",
    "        self.p_dropout = 0.5\n",
    "        self.num_downsamples = num_downsamples\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.ctx = ctx\n",
    "        with self.name_scope():\n",
    "            self.body = self.get_body(resnet_layer_id=resnet_layer_id)\n",
    "            self.encoders = gluon.nn.HybridSequential()\n",
    "            with self.encoders.name_scope():\n",
    "                for i in range(self.num_downsamples):\n",
    "                    encoder = self.get_encoder(rnn_hidden_states=rnn_hidden_states, rnn_layers=rnn_layers, max_seq_len=max_seq_len)\n",
    "                    self.encoders.add(encoder)\n",
    "            self.decoder = self.get_decoder()\n",
    "            self.downsampler = self.get_down_sampler(self.FEATURE_EXTRACTOR_FILTER)\n",
    "\n",
    "    def get_down_sampler(self, num_filters):\n",
    "        '''Creates a two-stacked Conv-BatchNorm-Relu and then a pooling layer to\n",
    "        downsample the image features by half.\n",
    " \n",
    "        Parameters\n",
    "        ----------\n",
    "        num_filters: int\n",
    "            To select the number of filters in used the downsampling convolutional layer.\n",
    "        Returns\n",
    "        -------\n",
    "        network: gluon.nn.HybridSequential\n",
    "            The downsampler network that decreases the width and height of the image features by half.\n",
    "        \n",
    "        '''\n",
    "        out = gluon.nn.HybridSequential()\n",
    "        with out.name_scope():\n",
    "            for _ in range(2):\n",
    "                out.add(gluon.nn.Conv2D(num_filters, 3, strides=1, padding=1))\n",
    "                out.add(gluon.nn.BatchNorm(in_channels=num_filters))\n",
    "                out.add(gluon.nn.Activation('relu'))\n",
    "            out.add(gluon.nn.MaxPool2D(2))\n",
    "            out.collect_params().initialize(mx.init.Normal(), ctx=self.ctx)\n",
    "        out.hybridize()\n",
    "        return out\n",
    "\n",
    "    def get_body(self, resnet_layer_id):\n",
    "        '''Create the feature extraction network based on resnet34.\n",
    "        The first layer of the res-net is converted into grayscale by averaging the weights of the 3 channels\n",
    "        of the original resnet.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        resnet_layer_id: int\n",
    "            The resnet_layer_id specifies which layer to take from \n",
    "            the bottom of the network.\n",
    "        Returns\n",
    "        -------\n",
    "        network: gluon.nn.HybridSequential\n",
    "            The body network for feature extraction based on resnet\n",
    "        '''\n",
    "        pretrained = resnet34_v1(pretrained=True, ctx=self.ctx)\n",
    "        pretrained_2 = resnet34_v1(pretrained=True, ctx=mx.cpu(0))\n",
    "        first_weights = pretrained_2.features[0].weight.data().mean(axis=1).expand_dims(axis=1)\n",
    "        # First weights could be replaced with individual channels.\n",
    "        \n",
    "       \tbody = gluon.nn.HybridSequential()\n",
    "        with body.name_scope():\n",
    "            first_layer = gluon.nn.Conv2D(channels=64, kernel_size=(7, 7), padding=(3, 3), strides=(2, 2), in_channels=1, use_bias=False)\n",
    "            first_layer.initialize(mx.init.Xavier(), ctx=self.ctx)\n",
    "            first_layer.weight.set_data(first_weights)\n",
    "            body.add(first_layer)\n",
    "            body.add(*pretrained.features[1:-resnet_layer_id])\n",
    "        return body\n",
    "\n",
    "    def get_encoder(self, rnn_hidden_states, rnn_layers, max_seq_len):\n",
    "        '''Creates an LSTM to learn the sequential component of the image features.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        rnn_hidden_states: int\n",
    "            The number of hidden states in the RNN\n",
    "            \n",
    "        rnn_layers: int\n",
    "            The number of layers to stack the RNN\n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        network: gluon.nn.Sequential\n",
    "            The encoder network to learn the sequential information of the image features\n",
    "        '''\n",
    "        encoder = gluon.nn.HybridSequential()\n",
    "        with encoder.name_scope():\n",
    "            encoder.add(EncoderLayer(hidden_states=rnn_hidden_states, rnn_layers=rnn_layers, max_seq_len=max_seq_len))\n",
    "            encoder.add(gluon.nn.Dropout(self.p_dropout))\n",
    "        encoder.collect_params().initialize(mx.init.Xavier(), ctx=self.ctx)\n",
    "        return encoder\n",
    "    \n",
    "    def get_decoder(self):\n",
    "        ''' Creates a network to convert the output of the encoder into characters.\n",
    "        '''\n",
    "        alphabet_size = len(alphabet_encoding) + 1\n",
    "        decoder = mx.gluon.nn.Dense(units=alphabet_size, flatten=False)\n",
    "        decoder.collect_params().initialize(mx.init.Xavier(), ctx=self.ctx)\n",
    "        return decoder\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        features = self.body(x)\n",
    "        hidden_states = []\n",
    "        hs = self.encoders[0](features)\n",
    "        hidden_states.append(hs)\n",
    "        for i, _ in enumerate(range(self.num_downsamples - 1)):\n",
    "            features = self.downsampler(features)\n",
    "            hs = self.encoders[i+1](features)\n",
    "            hidden_states.append(hs)\n",
    "        hs = F.concat(*hidden_states, dim=2)\n",
    "        output = self.decoder(hs)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image, label):\n",
    "    '''This function resizes the input image and converts so that it could be fed into the network.\n",
    "    Furthermore, the label (text) is one-hot encoded.\n",
    "    '''\n",
    "    image = np.expand_dims(image, axis=0).astype(np.float32) \n",
    "    if image[0, 0, 0] > 1:\n",
    "        image = image/255.\n",
    "    \n",
    "    #image = (image - 0.942532484060557) / 0.15926149044640417\n",
    "    label_encoded = np.zeros(max_seq_len, dtype=np.float32)-1\n",
    "    i = 0\n",
    "    for word in label:\n",
    "        word = word.replace(\"&quot\", r'\"')\n",
    "        word = word.replace(\"&amp\", r'&')\n",
    "        word = word.replace('\";', '\\\"')\n",
    "        for letter in word:\n",
    "            label_encoded[i] = alphabet_dict[letter]\n",
    "            i += 1\n",
    "    return image, label_encoded\n",
    "\n",
    "def decode(prediction):\n",
    "    '''Returns the string given one-hot encoded vectors.\n",
    "    '''\n",
    "    results = []\n",
    "    for word in prediction:\n",
    "        result = []\n",
    "        for i, index in enumerate(word):\n",
    "            if i < len(word) - 1 and word[i] == word[i+1] and word[-1] != -1: #Hack to decode label as well\n",
    "                continue\n",
    "            if index == len(alphabet_dict) or index == -1:\n",
    "                continue\n",
    "            else:\n",
    "                result.append(alphabet_encoding[int(index)])\n",
    "        results.append(result)\n",
    "    words = [''.join(word) for word in results]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(e, network, dataloader, trainer, log_dir, print_name, is_train):\n",
    "    total_loss = nd.zeros(1, ctx)\n",
    "    #print(\"Ctx is \",ctx)\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "        x = x.as_in_context(ctx)\n",
    "        y = y.as_in_context(ctx)\n",
    "\n",
    "        with autograd.record(train_mode=is_train):\n",
    "            output = network(x)\n",
    "            loss_ctc = ctc_loss(output, y)\n",
    "        #print(\"this 2\")\n",
    "\n",
    "        if is_train:\n",
    "            loss_ctc.backward()\n",
    "            trainer.step(x.shape[0])\n",
    "        #print(\"This 3\")\n",
    "\n",
    "        if i == 0 and e % send_image_every_n == 0 and e > 0:\n",
    "            predictions = output.softmax().topk(axis=2).asnumpy()\n",
    "            decoded_text = decode(predictions)\n",
    "            output_image = draw_text_on_image(x.asnumpy(), decoded_text)\n",
    "            output_image[output_image < 0] = 0\n",
    "            output_image[output_image > 1] = 1\n",
    "            print(\"{} first decoded text = {}\".format(print_name, decoded_text[0]))\n",
    "            with SummaryWriter(logdir=log_dir, verbose=False, flush_secs=5) as sw:\n",
    "                sw.add_image('bb_{}_image'.format(print_name), output_image, global_step=e)\n",
    "\n",
    "        total_loss += loss_ctc.mean()\n",
    "\n",
    "    epoch_loss = float(total_loss.asscalar())/len(dataloader)\n",
    "\n",
    "     with SummaryWriter(logdir=log_dir, verbose=False, flush_secs=5) as sw:\n",
    "        sw.add_scalar('loss', {print_name: epoch_loss}, global_step=e)\n",
    "\n",
    "    return epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ctx = mx.gpu()\n",
    "except Exception as e:\n",
    "    ctx = mx.cpu()\n",
    "print(\"ctx is \", ctx)\n",
    "\n",
    "epochs = 60\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "\n",
    "max_seq_len = 50\n",
    "print_every_n = 5\n",
    "send_image_every_n = 5\n",
    "\n",
    "num_downsamples = 2\n",
    "resnet_layer_id = 4\n",
    "lstm_hidden_states = 512\n",
    "lstm_layers = 2\n",
    "\n",
    "random_y_translation, random_x_translation = 0.03, 0.03\n",
    "random_y_scaling, random_x_scaling = 0.1, 0.1\n",
    "random_shearing = 0.7\n",
    "\n",
    "log_dir = \"./logs/handwriting_recognition\"\n",
    "checkpoint_dir = \"model_checkpoint\"\n",
    "checkpoint_name = \"handwriting.params\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReceiptDataset(gluon.data.Dataset):\n",
    "    \n",
    "    def __init__(self, path_to_data='results_test2/', split='train'):\n",
    "        f = open(path_to_data+'sample.txt', 'r')\n",
    "        self.data = []\n",
    "        lines = f.readlines()\n",
    "        if split == 'train':\n",
    "            lines = lines[:int(0.8*len(lines))]\n",
    "        elif split == 'test':\n",
    "            lines  = lines[int(0.8*len(lines)):]\n",
    "        else:\n",
    "            raise \"Wrong split, must be train or test\"\n",
    "        \n",
    "    for l in lines:\n",
    "            splits = l[:-1].split(' ')\n",
    "            filename = path_to_data+splits[0]\n",
    "            text = ' '.join(splits[1:])\n",
    "            self.data.append((filename, text))\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        filename, text = self.data[idx]\n",
    "        image =  cv2.imread(filename, 0)\n",
    "        return resize_image(np.expand_dims(image, axis=2), (60,200))[0], text\n",
    "        \n",
    "    def __len__(self):\n",
    "        return  len(self.data)\n",
    "\n",
    "train_ds = ReceiptDataset(split='train')\n",
    "test_ds = ReceiptDataset(split='test')\n",
    "\n",
    "print(\"Number of training samples: {}\".format(len(train_ds)))\n",
    "print(\"Number of testing samples: {}\".format(len(test_ds)))\n",
    "train_data = gluon.data.DataLoader(train_ds.transform(transform), batch_size, shuffle=True, last_batch=\"rollover\", num_workers=4)\n",
    "test_data = gluon.data.DataLoader(test_ds.transform(transform), batch_size, shuffle=True, last_batch=\"keep\", num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNNBiLSTM(num_downsamples=num_downsamples, resnet_layer_id=resnet_layer_id , rnn_hidden_states=lstm_hidden_states, rnn_layers=lstm_layers, max_seq_len=max_seq_len, ctx=ctx)\n",
    "net.hybridize()\n",
    "ctc_loss = gluon.loss.CTCLoss(weight=0.2)\n",
    "best_test_loss = 10e5\n",
    "\n",
    "if False and (os.path.isfile(os.path.join(checkpoint_dir, checkpoint_name))):\n",
    "    net.load_parameters(os.path.join(checkpoint_dir, checkpoint_name))\n",
    "    print(\"Parameters loaded\")\n",
    "    print(run_epoch(0, net, test_data, None, log_dir, print_name=\"pretrained\", is_train=False))\n",
    "\n",
    "pretrained = \"models/handwriting_line8.params\"\n",
    "if False and (os.path.isfile(pretrained)):\n",
    "    net.load_parameters(pretrained, ctx=ctx)\n",
    "    print(\"Parameters loaded\")\n",
    "    print(run_epoch(0, net, test_data, None, log_dir, print_name=\"pretrained\", is_train=False))\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': 0.0001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epochs):\n",
    "    print(\"Running this train_loss\")\n",
    "    train_loss = run_epoch(e, net, train_data, trainer, log_dir, print_name=\"train\", is_train=True)\n",
    "    print(\"Running this test_loss\")\n",
    "    test_loss = run_epoch(e, net, test_data, trainer, log_dir, print_name=\"test\", is_train=False)\n",
    "        print(\"Running this test_loss\")\n",
    "    test_loss = run_epoch(e, net, test_data, trainer, log_dir, print_name=\"test\", is_train=False)    \n",
    "    if test_loss < best_test_loss:\n",
    "        print(\"Saving network, previous best test loss {:.6f}, current test loss {:.6f}\".format(best_test_loss, test_loss))\n",
    "        net.save_parameters(os.path.join(checkpoint_dir, checkpoint_name))\n",
    "        best_test_loss = test_loss\n",
    "        \n",
    "    if e % print_every_n == 0 and e > 0:\n",
    "        print(\"Epoch {0}, train_loss {1:.6f}, test_loss {2:.6f}\".format(e, train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_to_plot = 10\n",
    "\n",
    "for i in range(figs_to_plot):\n",
    "    n = int(random.random()*len(test_ds))\n",
    "    image, actual_label = test_ds[n]\n",
    "    #print(image)\n",
    "    image, _ = transform(image, actual_label)\n",
    "    #print(\"Image:\\n\",image)\n",
    "    image = nd.array(image)\n",
    "    image = image.as_in_context(ctx)\n",
    "    image = image.expand_dims(axis=0)\n",
    "    output = net(image)\n",
    "    #print(output)\n",
    "    predictions = output.softmax().topk(axis=2).asnumpy()\n",
    "    #print(predictions)\n",
    "    decoded_prediction_text = decode(predictions)[0]\n",
    "    print(\"decoded prediction text\", decoded_prediction_text)\n",
    "    print(\"label:\",actual_label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
